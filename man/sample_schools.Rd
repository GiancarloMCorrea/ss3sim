% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sample_schools.R
\name{sample_schools}
\alias{sample_schools}
\title{Sample length compositions from a single vector of expected values
 accounting for empirical aggregation patterns (or schools).}
\usage{
sample_schools(probs, Nhauls, Nsamp, vec, cl_factor = 1,
  vals_at_cutoff = 0.05, gamma_sh = NULL, gamma_ra = NULL,
  plot.schools = F, yr = NULL)
}
\arguments{
\item{probs}{vector of probabilities at length (length composition vector)}

\item{Nhauls}{number of hauls to sample lengths data from}

\item{Nsamp}{number of length samples to take from each haul}

\item{vec}{vector of length bins corresponding to the probabilities}

\item{cl_factor}{this parameter determines the characteristics of the
clusters (or fish schools) that form the overall distribution (combined by 
mixture distribution). \code{cl_factor} sets the maximum number of 
clusters that can be used to fit the expected length distribution 
\code{probs} and sets the mean length of these clusters. The number of 
clusters is defined by \code{cl_factor}*(max(\code{vec})-min(\code{vec})).
A value of \code{cl_factor}=1 means that the number of clusters will be 
equal to the range of lengths, i.e. the mean of each underlying distribution 
will be 1 cm apart. A value of 0.5 means that the number of clusters will be 
divided by 2, i.e. mean length of each distribution every 2cm etc.
Each cluster is the gamma equivalent of a normal distribution (gamma 
equivalent is used to avoid drawing negative length values). 
Using empirical \code{gamma_sh} and \code{gamma_ra} will overwrite the  
\code{cl_factor}.}

\item{vals_at_cutoff}{THIS ARGUMENT SHOULD BE RENAME (LEGACY) Value used to 
estimate the SD of the clusters (or fish schools), whose means are defined 
by \code{cl_factor}. A value of 0.2 means that the SD of the normal 
distributions will be 20 percent of the full range of lengths given 
by \code{vec}. 
Using \code{gamma_sh} and \code{gamma_ra} will overwrite the  
\code{vals_at_cutoff}.}

\item{gamma_sh}{vector of shape parameters for the gamma distributions of the 
clusters. Use with \code{gamma_ra}. If used, these arguments will overwrite 
\code{cl_factor} and \code{vals_at_cutoff}. Default is NULL.}

\item{gamma_ra}{vector of rate parameters for the gamma distributions of the 
clusters. Use with \code{gamma_sh}. If used, these arguments will overwrite 
\code{cl_factor} and \code{vals_at_cutoff}. Default is NULL.}

\item{plot.schools}{Default is NULL. Set to TRUE to visualise the schools
fitting process.}

\item{yr}{Specify the year of the data. This is for plotting purposes only. 
Useful in the context of full simulations using \code{\link{ss3sim_base}}.}
}
\value{
A list of 2 objects. The first one is the resulting sampled length 
 composition, the second one is a dataframe detailing the actual sampling, 
 i.e. lengths measurements on a haul by haul basis.
}
\description{
Takes a vector of probabilities, which can be extracted from the
 \code{lencomp} component of a \code{data.SS_new} file containing expected
 values, and sampleS a number of draws (or hauls) of observed length
 compositions, accounting for autocorrelation in hauls, using a mixture 
 distribution approach.
}
\details{
The function can be used independantly but was specifically written 
 to be integrated into \code{\link{sample_lcomp}}. It is advised to use the 
 \code{parallel_lgths} option when turning the schooling option on in 
 \code{\link{sample_lcomp}}.
}
\note{
The shape \code{gamma_sh} and rate \code{gamma_ra} parameters can be 
obtained with \code{\link{schooling_pattern}} prior to using 
\code{\link{sample_schools}}, as in \code{\link{sample_lcomp}}.  
Using \code{gamma_sh} and \code{gamma_ra} allows the direct use of empirical 
data. \code{cl_factor} and \code{vals_at_cutoff} are an alternative to create 
clusters based on some functional definition of the link between mean 
length in the hauls and standard deviations, they do not require empirical 
data. Note - THERE is a warning sign, from ADMB, that can be safely ignored.
}
\examples{
 d <- system.file("extdata", package = "ss3sim")
 f_in <- paste0(d, "/models/cod-om/codOM.dat")
 dat_list <- r4ss::SS_readdat(f_in, verbose = FALSE)
 dat_list <- change_fltname(dat_list)
 \dontrun{
 # Option to sample in schools (length aggregated fish)
 
 # getwd()
 probs <- as.numeric(dat_list$lencomp[dat_list$lencomp$Yr ==95 & 
                                  dat_list$lencomp$FltSvy ==2,-c(1:6)])
 vec   <- dat_list$lbin_vector
 ex1   <- sample_schools(probs=probs, Nhauls= 300, Nsamp=100, vec=vec,
                      cl_factor = 0.5, vals_at_cutoff = 0.1,
                      plot.schools = TRUE,  yr=95)
                      
 ### THERE IS A PROBLEM WITH THE EXTREME SIZES THAT I DID NOT HAVE
 ### WHEN I WAS TWEEKING THE DATA FROM NORMAL TO MULTINOMIAL -
 ### WILL HAVE TO LOOK INTO THIS CLOSER !!!!!!!!!!!!!!!
 ### SHOULD ALL THE SIZES BELOW THE MINIMUM SIZE BIN SHOULD BE DISCARDED
 ### RATHER THAN SUMMED UP INTO THAT BIN? ... WHAT ABOUT THE MAX SIZE?
 
 # dat file
 ex1a <- ex1[[1]]
 # hauls file
 ex1b <- ex1[[2]]
 }
 
}
\seealso{
Other sampling functions: \code{\link{clean_data}},
  \code{\link{sample_agecomp}},
  \code{\link{sample_calcomp}}, \code{\link{sample_index}},
  \code{\link{sample_lcomp}}, \code{\link{sample_mlacomp}},
  \code{\link{sample_wtatage}},
  \code{\link{schooling_pattern}}
}
\author{
Gwladys Lambert
}
